{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c692ab04-e320-441f-9e2f-a06c6fbacea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473b99a8-c8bf-460c-b912-a962dfe4950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NISCHAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NISCHAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NISCHAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Optional import of sentence-transformers with compatibility message\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "except ImportError:\n",
    "    embedding_model = None\n",
    "    print(\"⚠️ sentence-transformers not installed or incompatible. Please install with:\")\n",
    "    print(\"pip install -U sentence-transformers huggingface-hub transformers\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bac61a8-945d-4425-b469-5c7209a3d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\chatbot\\20200325_counsel_chat.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4325be40-4a9d-4297-8ff7-97e88ad85000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['questionText'] = df['questionText'].apply(clean_text)\n",
    "df['answerText'] = df['answerText'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f56729dc-ea17-4600-b484-3d8014ec931b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_toc.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels\n",
    "X = df['questionText']\n",
    "y = df['topic']\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "joblib.dump(le, 'label_encoder_toc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aae0b58-df8e-4277-96d9-dab2456f2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding questions and answers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b9aa94af4043fea75d355afc55d4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a908c860b146deb9ea1a9a30fb355a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query: How do I handle depression and anxiety?\n",
      "\n",
      "Most Similar Question:\n",
      "→ dealing depression anxiety number year medication lately depression felt worse counseling help\n",
      "→ thank asking important question find three step getting ready treatment step one expressing interest wanting receiving treatment outcome positive behavioral change congratulation first step showing readiness start counseling asking question second step find counselor specializes treating client anxiety depression therapeutic orientation found helpful treating client anxiety depression combination cognitive behavioral therapy mindfulness solution focused brief therapy receiving meditation symptom part treatment part receiving counseling increase resilience future event research found medication psychotherapy treatment together show effective outcome depression third step increase positive selftalk motivate attend treatment counselor aware anxiety fear associated talking new professional first time however remind improve well hope helpful good luck treatment journey\n"
     ]
    }
   ],
   "source": [
    "if embedding_model:\n",
    "    print(\"Encoding questions and answers...\")\n",
    "    question_embeddings = embedding_model.encode(X.tolist(), show_progress_bar=True)\n",
    "    answer_embeddings = embedding_model.encode(df['answerText'].tolist(), show_progress_bar=True)\n",
    "\n",
    "    # Save embeddings\n",
    "    os.makedirs(\"model\", exist_ok=True)\n",
    "    joblib.dump(question_embeddings, 'model/toc_question_embeddings.dump')\n",
    "    joblib.dump(answer_embeddings, 'model/toc_answer_embeddings.dump')\n",
    "\n",
    "    # Save topic-answer map\n",
    "    topic_answer_map = {}\n",
    "    for topic, answer in zip(df['topic'], df['answerText']):\n",
    "        topic_answer_map.setdefault(topic, []).append(answer)\n",
    "    with open(\"model/toc_topic_answers.pkl\", \"wb\") as f:\n",
    "        pickle.dump(topic_answer_map, f)\n",
    "\n",
    "    # Sample retrieval function\n",
    "    def retrieve_similar_question(user_query):\n",
    "        print(f\"\\nUser Query: {user_query}\")\n",
    "        query_embedding = embedding_model.encode([clean_text(user_query)])\n",
    "        sims = cosine_similarity(query_embedding, question_embeddings)[0]\n",
    "        top_idx = np.argmax(sims)\n",
    "        print(\"\\nMost Similar Question:\")\n",
    "        print(f\"→ {df.iloc[top_idx]['questionText']}\\n→ {df.iloc[top_idx]['answerText']}\")\n",
    "\n",
    "    # Example usage\n",
    "    retrieve_similar_question(\"How do I handle depression and anxiety?\")\n",
    "else:\n",
    "    print(\"SentenceTransformer model is unavailable. Skipping embedding and retrieval.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c661779-6a0a-4de1-ae3d-40abf79db523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9224c-aca7-4d35-83bc-9dac00a1b957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ",
   "language": "python",
   "name": "mentalhealth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
